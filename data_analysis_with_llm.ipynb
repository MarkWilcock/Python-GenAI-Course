{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Analysis With LLMs\n",
    "\n",
    " parts were originally based on Datacamp's code-along \"Introduction to Large Language Models with GPT & LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install plotly, pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # Load the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set openai.api_key to the OPENAI_API_KEY environment variable\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the langchain package as lc\n",
    "import langchain as lc\n",
    "\n",
    "# From the langchain.chat_models module, import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# From the langchain.schema module, import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Import pandas using the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Import plotly.express using the alias px\n",
    "import plotly.express as px\n",
    "\n",
    "# From the IPython.display package, import display and Markdown\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a small fictitious dataset of patient hospital stays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_stay = pd.read_csv(\"resources/patient-stay.csv\")\n",
    "\n",
    "# Display a description of the numeric columns\n",
    "print(\"Description of numeric columns\\n\")\n",
    "display(df_patient_stay.describe())\n",
    "\n",
    "# Display a description of the text (object) columns\n",
    "print(\"Description of text columns\\n\")\n",
    "display(df_patient_stay.describe(include=\"O\"))\n",
    "\n",
    "# Print the whole dataset\n",
    "print(\"The first few rows\\n\")\n",
    "df_patient_stay.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask ChatGPT a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the system message. \n",
    "system_msg_test = \"\"\"You are a helpful assistant who understands data analysis.\n",
    " You write in a clear language that a ten year old can understand.\n",
    " You keep your answers brief.\"\"\"\n",
    "\n",
    "# Define the user message.\n",
    "user_msg_test = \"Tell me some uses of ChatGPT for data analysis.\"\n",
    "\n",
    "# Create a message list from the system and user messages. Assign to msgs_test.\n",
    "msgs_test = [\n",
    "    {\"role\": \"system\", \"content\": system_msg_test},\n",
    "    {\"role\": \"user\", \"content\": user_msg_test}\n",
    "]\n",
    "\n",
    "# Send the messages to GPT. Assign to response_test.\n",
    "response_test = completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=msgs_test\n",
    ")\n",
    "\n",
    "print(\"The entire response\\n\")\n",
    "display(response_test.model_dump_json())\n",
    "print(\"\\n\\n\")\n",
    "print(\"The response's content\\n\")\n",
    "print(response_test.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a Question About the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A description of the dataset\n",
    "dataset_description = \n",
    "\"\"\"\n",
    "The PatientStay table represents patients admitted to a ward in a hospital. \n",
    "Each row in the table represents a patient admission. \n",
    "The dataset contains the following columns.\n",
    "- PatientId (int): The unique ID of the patient.\n",
    "- AdmittedDate (date): The date on which the patient was admitted to the hospital.\n",
    "- DischargeDate (date): The date on which the patient was discharged from the hospital.\n",
    "- Hospital (varchar): The name of the hospital.\n",
    "- Ward (varchar): The name of the ward.\n",
    "- Tariff (float): The cost to treat the patient.\n",
    "- Ethnicity (varchar): The ethnicity of the patient e.g., White, Asian. For some rows this value is missing (null).\n",
    "\"\"\"\n",
    "\n",
    "# Create a task for the AI. Assign to suggest_questions.\n",
    "suggest_questions = \"Suggest some data analysis questions that could be answered with this dataset.\"\n",
    "\n",
    "# Concatenate the dataset description and the request. Assign to msgs_suggest_questions.\n",
    "msgs_suggest_questions = [\n",
    "    SystemMessage(content=\"You are a data analysis expert.\"),\n",
    "    HumanMessage(content=f\"{dataset_description}\\n\\n{suggest_questions}\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()\n",
    "response_suggest_questions = chat(msgs_suggest_questions)\n",
    "\n",
    "# Print the response\n",
    "print(\"The entire response\\n\")\n",
    "print(response_suggest_questions)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"The response's content\\n\")\n",
    "print(response_suggest_questions.content)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"The type of the response\\n\")\n",
    "print(type(response_suggest_questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold a conversation with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the response and a new message to the previous messages. \n",
    "# Assign to msgs_python_top_models.\n",
    "msgs_python_top_patients = msgs_suggest_questions + [\n",
    "    response_suggest_questions,\n",
    "    HumanMessage(\n",
    "        content=\"Write some Python code to find the 5 patients with the highest tariff.\")\n",
    "]\n",
    "\n",
    "# Pass your message to GPT. Assign to response_python_top_models.\n",
    "response_python_top_patients = chat(msgs_python_top_patients)\n",
    "\n",
    "# Display the response's Markdown content\n",
    "display(Markdown(response_python_top_patients.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
