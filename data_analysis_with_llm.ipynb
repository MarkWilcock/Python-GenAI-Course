{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Analysis With LLMs\n",
    "\n",
    "This was originally based on Datacamp's code-along \"Introduction to Large Language Models with GPT & LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # Load the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain useful for simplifying calls, swap LLMs, and more\n",
    "#!pip install langchain\n",
    "\n",
    "# Update the typing_extensions package\n",
    "#%pip install typing_extensions==4.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set openai.api_key to the OPENAI_API_KEY environment variable\n",
    "openai.api_key = os.environ[\"OPENAI_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the langchain package as lc\n",
    "import langchain as lc\n",
    "\n",
    "# From the langchain.chat_models module, import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# From the langchain.schema module, import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas using the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Import plotly.express using the alias px\n",
    "import plotly.express as px\n",
    "\n",
    "# From the IPython.display package, import display and Markdown\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from electric_cars.csv. Assign to electric_cars.\n",
    "electric_cars = pd.read_csv(\"electric_cars.csv\")\n",
    "\n",
    "# Display a description of the numeric columns\n",
    "print(\"Description of numeric columns\\n\")\n",
    "display(electric_cars.describe())\n",
    "\n",
    "# Display a description of the text (object) columns\n",
    "print(\"Description of text columns\\n\")\n",
    "display(electric_cars.describe(include=\"O\"))\n",
    "\n",
    "# Print the whole dataset\n",
    "print(\"The electric cars dataset\\n\")\n",
    "electric_cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking GPT a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ['OPENAI_KEY'])\n",
    "\n",
    "# Define the system message. Assign to system_msg_test.\n",
    "system_msg_test = \"\"\"You are a helpful assistant who understands data science.\n",
    " You write in a clear language that a ten year old can understand.\n",
    " You keep your answers brief.\"\"\"\n",
    "\n",
    "# Define the user message. Assign to user_msg_test.\n",
    "user_msg_test = \"Tell me some uses of GPT for data analysis.\"\n",
    "\n",
    "# Create a message list from the system and user messages. Assign to msgs_test.\n",
    "msgs_test = [\n",
    "    {\"role\": \"system\", \"content\": system_msg_test},\n",
    "    {\"role\": \"user\", \"content\": user_msg_test}\n",
    "]\n",
    "\n",
    "# Send the messages to GPT. Assign to rsps_test.\n",
    "rsps_test = completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=msgs_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the whole response\n",
    "print(\"The whole response\\n\")\n",
    "display(rsps_test.model_dump_json())\n",
    "\n",
    "print(\"\\n\\n----\\n\\n\")\n",
    "\n",
    "# Print just the response's content\n",
    "print(\"Just the response's content\\n\")\n",
    "print(rsps_test.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Asking a Question About the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A description of the dataset\n",
    "dataset_description = \"\"\"\n",
    "You have a dataset about electric cars registered in Washington state, USA in 2020. It is available as a pandas DataFrame named `electric_cars`.\n",
    "\n",
    "Each row in the dataset represents the count of the number of cars registered within a city, for a particular model.\n",
    "\n",
    "The dataset contains the following columns.\n",
    "\n",
    "- `city` (character): The city in which the registered owner resides.\n",
    "- `county` (character): The county in which the registered owner resides.\n",
    "- `model_year` (integer): The [model year](https://en.wikipedia.org/wiki/Model_year#United_States_and_Canada) of the car.\n",
    "- `make` (character): The manufacturer of the car.\n",
    "- `model` (character): The model of the car.\n",
    "- `electric_vehicle_type` (character): Either \"Plug-in Hybrid Electric Vehicle (PHEV)\" or \"Battery Electric Vehicle (BEV)\".\n",
    "- `n_cars` (integer): The count of the number of vehicles registered.\n",
    "\"\"\"\n",
    "\n",
    "# Create a task for the AI. Assign to suggest_questions.\n",
    "suggest_questions = \"Suggest some data analysis questions that could be answered with this dataset.\"\n",
    "\n",
    "# Concatenate the dataset description and the request. Assign to msgs_suggest_questions.\n",
    "msgs_suggest_questions = [\n",
    "    SystemMessage(content=\"You are a data analysis expert.\"),\n",
    "    HumanMessage(content=f\"{dataset_description}\\n\\n{suggest_questions}\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(openai_api_key=os.environ['OPENAI_KEY'])\n",
    "rsps_suggest_questions = chat(msgs_suggest_questions)\n",
    "# Print the response\n",
    "print(\"The whole response\\n\")\n",
    "print(rsps_suggest_questions)\n",
    "\n",
    "print(\"\\n----\\n\")\n",
    "\n",
    "# Print just the response's content\n",
    "print(\"Just the response's content\\n\")\n",
    "print(rsps_suggest_questions.content)\n",
    "\n",
    "print(\"\\n----\\n\")\n",
    "\n",
    "# Print the type of the response\n",
    "print(\"The type of the response\\n\")\n",
    "print(type(rsps_suggest_questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold a conversation with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the response and a new message to the previous messages. \n",
    "# Assign to msgs_python_top_models.\n",
    "msgs_python_top_models = msgs_suggest_questions + [\n",
    "    rsps_suggest_questions,\n",
    "    HumanMessage(content=\"Write some Python code to find the top 5 most popular make/model combinations of electric car in Washington.\")\n",
    "]\n",
    "\n",
    "# Pass your message to GPT. Assign to rsps_python_top_models.\n",
    "rsps_python_top_models = chat(msgs_python_top_models)\n",
    "\n",
    "# Display the response's Markdown content\n",
    "display(Markdown(rsps_python_top_models.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the code provided by GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by make and model, then sum the number of cars registered for each combination\n",
    "popular_make_model = electric_cars.groupby(['make', 'model'])['n_cars'].sum().reset_index()\n",
    "\n",
    "# Sort the data by the total number of cars registered in descending order\n",
    "popular_make_model = popular_make_model.sort_values(by='n_cars', ascending=False)\n",
    "\n",
    "# Get the top 5 most popular make/model combinations\n",
    "top_5_popular_make_model = popular_make_model.head(5)\n",
    "\n",
    "print(top_5_popular_make_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new OpenAI chat object with temperature set to zero. Assign to chat0.\n",
    "chat0 = ChatOpenAI(temperature=0, openai_api_key=os.environ['OPENAI_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask GPT for code for a bar plot, as detailed in the instructions\n",
    "msgs_python_plot = msgs_python_top_models + [\n",
    "    rsps_python_top_models,\n",
    "    HumanMessage(content=\"Write some Python code to draw a bar plot of the total count of electric cars by model year, with bars colored by electric vehicle type. Use the Plotly Express package.\")\n",
    "]\n",
    "\n",
    "rsps_python_plot = chat0(msgs_python_plot)\n",
    "\n",
    "display(Markdown(rsps_python_plot.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call GPT again with the same message list and display the response\n",
    "rsps_python_plot1 = chat0(msgs_python_plot)\n",
    "\n",
    "display(Markdown(rsps_python_plot1.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the code generated by GPT\n",
    "import plotly.express as px\n",
    "\n",
    "# Group the data by model year and electric vehicle type, then sum the number of cars registered for each group\n",
    "total_count_by_year_type = electric_cars.groupby(['model_year', 'electric_vehicle_type'])['n_cars'].sum().reset_index()\n",
    "\n",
    "# Plot the bar chart using Plotly Express\n",
    "fig = px.bar(total_count_by_year_type, x='model_year', y='n_cars', color='electric_vehicle_type',\n",
    "             labels={'model_year': 'Model Year', 'n_cars': 'Total Count of Electric Cars'},\n",
    "             title='Total Count of Electric Cars by Model Year',\n",
    "             barmode='group')\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
